% Abstract Section
\chapter*{ABSTRACT}
\addcontentsline{toc}{chapter}{ABSTRACT}

Organizations increasingly need to share sensitive tabular data for machine learning while protecting individual privacy. This project investigates diffusion models as a privacy-preserving approach for generating synthetic tabular data. We implement and evaluate TabDDPM-style diffusion with hybrid Gaussian-Multinomial noise handling, comparing it against CTGAN and SMOGN baselines. Our experiments on organizational datasets (sales quotation and manufacturing data from a fastener company) demonstrate that TabDDPM-style diffusion achieves 87-98\% of baseline model performance when training on synthetic data alone, significantly outperforming CTGAN (35\%) and SMOGN (which fails catastrophically on complex data). On the Production dataset (5,370 samples, 117 features), TabDDPM achieves 98.4\% of baseline, demonstrating strong generalization to complex real-world data. Privacy validation through membership inference attacks confirms that the generated data leaks no information about training records (AUC = 0.51, equivalent to random guessing). These results establish diffusion models as a superior approach for generating high-utility, privacy-preserving synthetic tabular data.
